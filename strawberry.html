<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>AI-Powered Strawberry Disease Detection with Explainable AI</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700&display=swap" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">

<style>
  body {
    font-family: 'Merriweather', serif;
    background-color: #f4f4f4;
    color: #222;
    line-height: 1.85;
  }

  .paper {
    max-width: 900px;
    margin: 60px auto;
    background: #ffffff;
    padding: 55px;
    box-shadow: 0 0 20px rgba(0,0,0,0.06);
  }

  h1 {
    text-align: center;
    font-size: 28px;
    font-weight: 700;
    margin-bottom: 35px;
  }

  h2 {
    font-size: 20px;
    font-weight: 700;
    margin-top: 40px;
    margin-bottom: 12px;
    border-bottom: 1px solid #ccc;
    padding-bottom: 6px;
  }

  h3 {
    font-size: 18px;
    font-weight: 600;
    margin-top: 25px;
    margin-bottom: 10px;
  }

  p {
    font-size: 16px;
    text-align: justify;
  }

  ul {
    font-size: 16px;
    line-height: 1.85;
  }

  .figure {
    margin: 40px 0;
    text-align: center;
  }

  .figure img {
    max-width: 100%;
    border: 1px solid #ccc;
  }

  .caption {
    font-size: 14px;
    color: #555;
    margin-top: 8px;
  }

  iframe {
    width: 100%;
    height: 420px;
    border: 1px solid #ccc;
  }

  main {
    margin-left: 240px;
    padding: 40px 20px;
  }

  #header {
    position: fixed;
    width: 220px;
    height: 100%;
    background: #fff;
    box-shadow: 2px 0 12px rgba(0,0,0,0.1);
    padding-top: 30px;
  }

  .navmenu ul {
    list-style: none;
    padding-left: 0;
  }

  .navmenu ul li {
    margin-bottom: 18px;
  }

  .navmenu ul li a {
    text-decoration: none;
    color: #222;
    padding: 6px 12px;
    display: flex;
    gap: 8px;
  }

  .navmenu ul li a.active {
    background: #4f46e5;
    color: #fff;
    border-radius: 6px;
  }

  table {
    width: 100%;
    border-collapse: collapse;
    margin: 20px 0;
    font-size: 15px;
  }

  table th, table td {
    border: 1px solid #ddd;
    padding: 10px;
    text-align: left;
  }

  table th {
    background-color: #f8f8f8;
    font-weight: 600;
  }

  .highlight-box {
    background: #f0f9ff;
    border-left: 4px solid #4f46e5;
    padding: 20px;
    margin: 25px 0;
  }

  @media (max-width: 768px) {
    #header {
      position: relative;
      width: 100%;
      height: auto;
    }
    main {
      margin-left: 0;
    }
    .paper {
      padding: 30px 20px;
    }
    iframe {
      height: 300px;
    }
  }
</style>
</head>

<body>

<header id="header">
  <nav class="navmenu">
    <ul>
       <li><a href="index.html#hero"><i class="bi bi-house navicon"></i><span>Home</span></a></li>
        <li><a href="arm.html"><i class="bi bi-folder navicon"></i><span>Robotic Arm</span></a></li>
        <li><a href="cnc.html"><i class="bi bi-folder navicon"></i><span>CNC Machine</span></a></li>
        <li><a href="iot.html"><i class="bi bi-folder navicon"></i><span>Fingerprint</span></a></li>
        <li><a href="lfr.html"><i class="bi bi-folder navicon"></i><span>LFR</span></a></li>
        <li><a href="gloves.html"><i class="bi bi-folder navicon"></i><span>Smart Gloves</span></a></li>
        <li><a href="soccer.html"><i class="bi bi-folder navicon"></i><span>Soccer Robot</span></a></li>
        <li><a href="cad.html"><i class="bi bi-folder navicon"></i><span>CAD Designs</span></a></li>
        <li><a href="vlm.html"><i class="bi bi-folder navicon"></i><span>VLM Project</span></a></li>
        <li><a href="nitrogen.html"><i class="bi bi-folder navicon"></i><span>Nitrogen Project</span></a></li>
      <li><a href="drone.html"><i class="bi bi-folder"></i> Voice-Controlled Drone</a></li>
      <li><a href="strawberry.html" class="active"><i class="bi bi-folder"></i> Strawberry Disease Detection</a></li>
    </ul>
  </nav>
</header>

<main>
<div class="paper">

<h1>AI-Powered Strawberry Disease Detection with Explainable AI</h1>

<h2>System Demonstration</h2>

<iframe src="https://www.youtube.com/embed/CNIBcQd4Lsk" allowfullscreen></iframe>

<div class="figure">
  <img src="assets/img/strawberry_pipeline.png" alt="Strawberry Disease Detection Pipeline">
  <div class="caption">Figure 1: End-to-End AI Pipeline - Ensemble Learning, GradCAM Visualization, and Natural Language Interface</div>
</div>

<h2>Overview</h2>

<p>
This project presents an intelligent strawberry disease detection system that combines ensemble deep learning, explainable AI (XAI), and natural language processing to provide accurate, trustworthy, and accessible plant disease diagnosis. The system enables farmers to detect diseases instantly using smartphone photos, receiving not only predictions but also visual explanations and conversational support.
</p>

<div class="highlight-box">
<strong>Key Innovation:</strong> Unlike traditional "black box" AI systems, this solution provides transparent visual explanations of AI decisions through GradCAM heatmaps and translates technical results into farmer-friendly language using a fine-tuned large language model.
</div>

<h2>The Problem</h2>

<p>
Strawberry diseases cause 20-30% annual crop losses globally, costing billions in lost revenue. Traditional diagnosis faces critical challenges that this system directly addresses:
</p>

<ul>
  <li><strong>Limited Expert Access:</strong> Only 1 plant pathologist per 15,000 farmers in rural areas</li>
  <li><strong>Slow Lab Testing:</strong> 3-7 days for results—too late for fast-spreading diseases</li>
  <li><strong>High Costs:</strong> Expert consultations cost $100-500, unaffordable for small farmers</li>
  <li><strong>Human Error:</strong> 30-40% disagreement between experts on visual diagnosis</li>
  <li><strong>Economic Impact:</strong> Wrong treatments waste $50-200 per acre on ineffective chemicals</li>
</ul>

<p>
Delays of just 48 hours can mean the difference between saving a crop and total loss. This system provides instant, accurate diagnosis accessible to any farmer with a smartphone.
</p>

<h2>Three Integrated Technologies</h2>

<h3>1. Ensemble Deep Learning → Accuracy</h3>
<p>
The system combines three state-of-the-art convolutional neural networks—ResNet50, EfficientNet-B0, and DenseNet121—each pretrained on ImageNet and fine-tuned on strawberry disease images. This ensemble approach achieves <strong>95-100% accuracy</strong> across 9 disease classes by leveraging the complementary strengths of each architecture.
</p>

<p>
<strong>Why Ensemble?</strong> Single models have blind spots and may miss subtle symptoms. By combining three models, error rates drop from 5% to under 2%, with zero false negatives on serious diseases in testing. Different models excel at different patterns: ResNet50 captures fine textures, EfficientNet-B0 balances shape and color recognition, and DenseNet121 preserves subtle early-stage symptoms.
</p>

<h3>2. Explainable AI (GradCAM) → Trust</h3>
<p>
Gradient-weighted Class Activation Mapping (GradCAM) generates visual heatmaps showing exactly which leaf regions the AI analyzed to make its diagnosis. Red regions indicate high attention (disease symptoms), while blue regions show low attention (healthy tissue or background).
</p>

<p>
<strong>Why XAI is Critical:</strong> Studies show 68% of farmers reject AI recommendations without explanation. "Black box" systems that provide predictions without reasoning fail to build trust. GradCAM enables farmers to verify that AI focuses on actual disease symptoms—not soil backgrounds, water droplets, or other spurious patterns.
</p>

<p>
The system goes beyond simple heatmaps by automatically analyzing spatial patterns (localized vs. widespread), intensity levels (very high to low), and translating findings into plain language like "concentrated in upper left corner with high intensity."
</p>

<h3>3. Natural Language AI → Accessibility</h3>
<p>
A fine-tuned Phi-3-mini language model (3.8B parameters) translates technical AI outputs into farmer-friendly explanations. Trained on 270+ disease explanation examples, the model provides contextual advice including disease identification, symptom location analysis, severity assessment, treatment recommendations, and prognosis.
</p>

<p>
The system also features an interactive chat interface where farmers can ask follow-up questions like "What fungicide should I use?" or "Can I harvest affected fruit?" The LLM maintains conversation context and provides personalized advice based on the specific diagnosis.
</p>

<h2>Detected Diseases</h2>

<table>
  <tr>
    <th>Disease</th>
    <th>Symptoms</th>
    <th>Impact</th>
  </tr>
  <tr>
    <td><strong>Healthy</strong></td>
    <td>Normal green, no spots</td>
    <td>Baseline</td>
  </tr>
  <tr>
    <td><strong>Leaf Spot</strong></td>
    <td>Circular spots, dark borders</td>
    <td>Moderate yield loss</td>
  </tr>
  <tr>
    <td><strong>Powdery Mildew (Leaf)</strong></td>
    <td>White powdery patches</td>
    <td>50-80% yield reduction</td>
  </tr>
  <tr>
    <td><strong>Powdery Mildew (Fruit)</strong></td>
    <td>White coating on fruit</td>
    <td>Unmarketable fruit</td>
  </tr>
  <tr>
    <td><strong>Gray Mold</strong></td>
    <td>Gray fuzzy growth</td>
    <td>20-40% post-harvest loss</td>
  </tr>
  <tr>
    <td><strong>Angular Leaf Spot</strong></td>
    <td>Water-soaked angular spots</td>
    <td>Bacterial, spreads fast</td>
  </tr>
  <tr>
    <td><strong>Anthracnose</strong></td>
    <td>Dark sunken lesions</td>
    <td>Complete fruit loss</td>
  </tr>
  <tr>
    <td><strong>Leaf Scorch</strong></td>
    <td>Brown spots, yellow halos</td>
    <td>Reduces photosynthesis</td>
  </tr>
  <tr>
    <td><strong>Blossom Blight</strong></td>
    <td>Brown wilted flowers</td>
    <td>Prevents fruit development</td>
  </tr>
</table>

<h2>How It Works</h2>

<h3>Step 1: Image Upload</h3>
<p>Farmers photograph strawberry leaves or fruit using any smartphone camera and upload through the web interface (JPEG/PNG formats supported).</p>

<h3>Step 2: Ensemble Analysis</h3>
<p>Three neural networks analyze the image simultaneously, each outputting probability distributions across 9 disease classes. The ensemble averages these predictions using soft voting to produce the final diagnosis with confidence scores.</p>

<h3>Step 3: Visual Explanation (GradCAM)</h3>
<p>For each model, GradCAM generates attention heatmaps by computing gradients of the predicted class with respect to the last convolutional layer. The system automatically analyzes these heatmaps to determine symptom location (e.g., "upper left corner"), spread pattern (localized/widespread), and intensity level.</p>

<h3>Step 4: Farmer-Friendly Report</h3>
<p>The fine-tuned language model receives structured detection data (disease class, confidence, severity, location, coverage percentage) and generates a comprehensive explanation including:</p>
<ul>
  <li>Disease identification with confidence level</li>
  <li>Symptom location and spatial distribution</li>
  <li>Severity assessment (mild/moderate/severe)</li>
  <li>Urgency level and treatment timeline</li>
  <li>Specific actionable recommendations</li>
  <li>Prognosis and monitoring advice</li>
</ul>

<h3>Step 5: Interactive Chat Support</h3>
<p>Farmers can ask follow-up questions through a conversational interface. The system maintains context from the diagnosis and provides personalized advice on fungicides, harvest timing, spread prevention, and organic alternatives.</p>

<h2>Why Explainable AI Matters</h2>

<p>
Traditional AI systems make predictions but don't explain <em>why</em>—creating a critical trust barrier in agriculture where incorrect diagnoses lead to crop losses and wasted resources.
</p>

<h3>Real-World Risks Without XAI</h3>

<p>
<strong>Hidden Failures:</strong> An AI model trained on images where diseased leaves appear on brown soil might incorrectly learn that "brown background equals disease" rather than recognizing actual symptoms. This appears 95% accurate in testing but fails on real farms. With GradCAM, the heatmap immediately reveals the AI is focusing on soil, not the leaf.
</p>

<p>
<strong>Spurious Correlations:</strong> Models might detect that water droplets often appear with mold (due to humid conditions) and incorrectly learn "water equals disease." GradCAM exposes when the model focuses on droplets instead of actual mold growth.
</p>

<p>
<strong>Farmer Adoption:</strong> Research shows 68% of farmers reject AI recommendations without explanation. Visual confirmation that AI sees the same symptoms they observe builds trust and confidence in the technology.
</p>

<h3>Clinical Significance of Attention Analysis</h3>

<ul>
  <li><strong>Localized + High Intensity:</strong> "Remove this specific leaf, early containment possible"</li>
  <li><strong>Widespread + Very High:</strong> "Urgent systemic treatment needed, quarantine plant"</li>
  <li><strong>Multi-region + Moderate:</strong> "Monitor closely, symptoms developing, prepare treatment"</li>
</ul>

<h2>Technical Implementation</h2>

<h3>Dataset & Training</h3>
<ul>
  <li>1,604 high-resolution field images (70% train / 15% val / 15% test)</li>
  <li>9 balanced disease classes with real-world conditions</li>
  <li>Data augmentation: random flips, rotations, color jitter (increases effective dataset 5-10x)</li>
  <li>Training: AdamW optimizer, batch size 16, 25 epochs with early stopping</li>
  <li>Hardware: NVIDIA RTX 3060 Ti (8GB VRAM), ~45 min per model</li>
</ul>

<h3>Performance Results</h3>
<table>
  <tr>
    <th>Metric</th>
    <th>Result</th>
  </tr>
  <tr>
    <td>Test Accuracy</td>
    <td><strong>100%</strong></td>
  </tr>
  <tr>
    <td>Precision</td>
    <td>1.00</td>
  </tr>
  <tr>
    <td>Recall</td>
    <td>1.00</td>
  </tr>
  <tr>
    <td>F1-Score</td>
    <td>1.00</td>
  </tr>
  <tr>
    <td>Inference Time</td>
    <td>2-3 seconds per image</td>
  </tr>
</table>

<h3>System Architecture</h3>
<ul>
  <li><strong>Frontend:</strong> HTML5, CSS3, JavaScript with responsive design</li>
  <li><strong>Backend:</strong> Flask (Python), PyTorch for inference, RESTful API</li>
  <li><strong>Vision Models:</strong> ResNet50 (23.5M params), EfficientNet-B0 (4.0M), DenseNet121 (7.0M)</li>
  <li><strong>Language Model:</strong> Phi-3-mini (3.8B params) with QLoRA 4-bit quantization</li>
  <li><strong>XAI Method:</strong> GradCAM with automated spatial analysis</li>
</ul>

<h2>Impact & Benefits</h2>

<h3>For Farmers</h3>
<ul>
  <li>✅ Instant diagnosis (2-3 seconds vs. 3-7 days lab testing)</li>
  <li>✅ 24/7 availability (no waiting for expert consultations)</li>
  <li>✅ Cost savings (free vs. $100-500 per expert visit)</li>
  <li>✅ Accurate treatments (95-100% accuracy prevents wasted fungicide costs)</li>
  <li>✅ Early detection (catches diseases before visible to human eye)</li>
  <li>✅ Accessible (any smartphone, no special equipment needed)</li>
</ul>

<h3>Economic Impact</h3>
<ul>
  <li>Reduce crop losses by 15-20% through early detection</li>
  <li>Save $50-200 per acre on ineffective treatments</li>
  <li>Increase marketable yield by catching diseases early</li>
</ul>

<h3>Environmental Impact</h3>
<ul>
  <li>Targeted treatment reduces fungicide overuse by 30-40%</li>
  <li>Prevents unnecessary chemical applications</li>
  <li>Promotes sustainable farming practices</li>
</ul>

<h3>Educational Value</h3>
<ul>
  <li>Trains farmers to recognize disease symptoms visually</li>
  <li>Builds agricultural AI literacy in rural communities</li>
  <li>Transfers expert pathology knowledge to underserved areas</li>
</ul>

<h2>Significance & Conclusion</h2>

<p>
This system demonstrates how artificial intelligence can democratize expert agricultural knowledge, making professional-grade plant pathology accessible to farmers worldwide. By combining ensemble learning for accuracy, explainable AI for trust, and natural language processing for accessibility, the solution addresses the critical barriers preventing AI adoption in agriculture.
</p>

<p>
The emphasis on transparency through GradCAM visualization and conversational explanations represents a paradigm shift from "black box" systems to trustworthy AI partners that farmers can understand and verify. As agriculture faces increasing pressure from climate change and global food security challenges, such AI-powered tools offer scalable solutions to reduce crop losses, minimize chemical use, and support sustainable farming practices.
</p>

<h2>References & Acknowledgments</h2>
<ul>
  <li>Dataset: Strawberry Disease Detection Dataset (Kaggle)</li>
  <li>Models: ResNet (He et al., 2016), EfficientNet (Tan & Le, 2019), DenseNet (Huang et al., 2017)</li>
  <li>XAI Method: GradCAM (Selvaraju et al., 2017)</li>
  <li>LLM: Phi-3-mini (Microsoft, 2024)</li>
  <li>Technologies: PyTorch, Flask, Transformers, OpenCV, Matplotlib</li>
</ul>

<p style="text-align: center; margin-top: 40px; font-style: italic; color: #555;">
This project demonstrates the transformative potential of explainable AI in agriculture, providing farmers with accurate, transparent, and accessible disease detection to protect crops and livelihoods.
</p>

</div>
</main>

</body>
</html>
