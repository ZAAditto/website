<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>VLM Project</title>

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/projcet.css" rel="stylesheet">

  <style>
    iframe {
      width: 100%;
      height: 350px;
      border-radius: 10px;
      border: none;
    }

    /* More vertical layout for YouTube Shorts */
    iframe.vlm-shorts {
      max-width: 420px;
      aspect-ratio: 9 / 16;
      height: auto;           /* let aspect-ratio handle height */
      display: block;
      margin: 0 auto;
    }
  </style>
</head>

<body class="portfolio-details-page">

  <!-- Header -->
  <header id="header" class="header d-flex flex-column justify-content-center">
    <i class="header-toggle d-xl-none bi bi-list"></i>
    <nav id="navmenu" class="navmenu">
      <ul>
        <li><a href="index.html#hero"><i class="bi bi-house navicon"></i><span>Home</span></a></li>
        <li><a href="arm.html"><i class="bi bi-folder navicon"></i><span>Robotic Arm</span></a></li>
        <li><a href="cnc.html"><i class="bi bi-folder navicon"></i><span>CNC Machine</span></a></li>
        <li><a href="iot.html"><i class="bi bi-folder navicon"></i><span>Fingerprint</span></a></li>
        <li><a href="lfr.html"><i class="bi bi-folder navicon"></i><span>LFR</span></a></li>
        <li><a href="gloves.html"><i class="bi bi-folder navicon"></i><span>Smart Gloves</span></a></li>
        <li><a href="soccer.html"><i class="bi bi-folder navicon"></i><span>Soccer Robot</span></a></li>
        <li><a href="cad.html"><i class="bi bi-folder navicon"></i><span>CAD Designs</span></a></li>
        <li><a href="vlm.html" class="active"><i class="bi bi-folder navicon"></i><span>VLM Project</span></a></li>
      </ul>
    </nav>
  </header>

  <!-- Main -->
  <main class="main">

    <!-- Title -->
    <div class="page-title-custom" data-aos="fade">
      <div class="container">
        <h1>Visual Language Model (VLM) Project</h1>
      </div>
    </div>

    <!-- Portfolio Section -->
    <section id="portfolio-details" class="portfolio-details section">
      <div class="container" data-aos="fade-up">

        <div class="portfolio-description about-description">

          <h2>Vision-Language Model (VLM) Research Prototype</h2>

          <p>
            I have developed a <strong>500M-parameter Vision–Language Model (VLM)</strong> designed as a lightweight yet capable system
            for real-time visual understanding. The model is optimized to run efficiently on consumer-grade GPUs and can be deployed
            on mobile devices through a custom Flask-based streaming interface, enabling flexible field use with only a smartphone camera.
          </p>

          <p>
            Although the current version functions as a <strong>general-purpose perception model</strong>—able to recognize everyday
            objects such as furniture, tools, fruits, and common household items—it is architected for <strong>task-specific fine-tuning</strong>.
            This makes it suitable for a wide range of research and applied domains.
          </p>

          <h3>Potential Specialized Applications</h3>
          <p>The model can be fine-tuned for domain-specific tasks, including:</p>

          <h4>Precision Agriculture</h4>
          <ul>
            <li>Crop disease identification (leaf spots, blights, nutrient deficiencies)</li>
            <li>Yield estimation from in-field imagery</li>
            <li>Weed detection and species classification</li>
            <li>Fruit maturity assessment</li>
            <li>Soil condition assessment</li>
          </ul>

          <h4>Robotics, Perception &amp; Navigation</h4>
          <ul>
            <li>Semantic scene understanding for mobile robots</li>
            <li>Object detection &amp; tracking for manipulation tasks</li>
            <li>Vision-based SLAM enhancements with multimodal reasoning</li>
            <li>Human–robot interaction through natural-language query and explanation</li>
            <li>Environment-aware path planning based on visual prompts</li>
          </ul>

          <h4>Mechanical &amp; Industrial Engineering</h4>
          <ul>
            <li>Visual quality inspection in manufacturing lines</li>
            <li>Defect detection on surfaces and components</li>
            <li>Tool/part recognition for automated assembly</li>
            <li>Monitoring of machine states through visual cues</li>
            <li>Safety compliance detection (gear, posture, hazard identification)</li>
          </ul>

          <h3>Technical Overview</h3>
          <ul>
            <li><strong>Model size:</strong> 500M parameters (efficient for edge and mid-range GPU deployment)</li>
            <li><strong>Capabilities:</strong> Natural-language grounding, object identification, visual reasoning</li>
            <li><strong>Deployment:</strong> Runs locally on GPU/CPU; accessed on mobile via low-latency Flask server</li>
          </ul>

          <h3>Why This Matters</h3>
          <p>
            This VLM demonstrates how compact multimodal models can provide high-quality perception without relying on large cloud
            infrastructures. The system is particularly suitable for field robotics and precision agriculture, where bandwidth,
            privacy, and real-time performance are critical.
          </p>
          <p>
            It also serves as a foundation for future research into:
          </p>
          <ul>
            <li>Edge-based intelligent crop monitoring</li>
            <li>Autonomous robotic manipulation</li>
            <li>Multimodal reasoning for environmental understanding</li>
            <li>On-device visual analytics for low-resource settings</li>
          </ul>

          <!-- Video -->
          <div class="mt-4">
            <p><strong>Project Demo:</strong></p>
            <iframe
              class="vlm-shorts"
              src="https://www.youtube.com/embed/sGccE8utyrg"
              title="VLM Demo"
              allowfullscreen>
            </iframe>
          </div>

        </div>

      </div>
    </section>

    <!-- Footer -->
    <footer id="footer" class="footer position-relative light-background">
      <div class="container">
        <div class="credits">
          © 2025 Zubayer Ahmed Aditto. All Rights Reserved.
        </div>
      </div>
    </footer>

    <!-- Scroll Top -->
    <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center">
      <i class="bi bi-arrow-up-short"></i>
    </a>

    <!-- Preloader -->
    <div id="preloader"></div>

    <!-- Vendor JS Files -->
    <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <script src="assets/vendor/php-email-form/validate.js"></script>
    <script src="assets/vendor/aos/aos.js"></script>
    <script src="assets/vendor/typed.js/typed.umd.js"></script>
    <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
    <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
    <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
    <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
    <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
    <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

    <!-- Main JS File -->
    <script src="assets/js/main.js"></script>

</body>
</html>
